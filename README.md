

## Multimodal Sentiment Analysis (MSA) 

 - Mmlatch: Bottom-Up Top-Down Fusion For Multimodal Sentiment Analysis. ICASSP2022. [[paper]](https://arxiv.org/pdf/2201.09828.pdf) [[code]](https://github.com/yaohungt/Multimodal-Transformer)

 - Multi-Channel Attentive Graph Convolutional Network with Sentiment Fusion for Multimodal Sentiment Analysis. ICASSP2022. [[paper]](https://arxiv.org/pdf/2201.10274.pdf)

 - Improving Multimodal Fusion with Hierarchical Mutual Information Maximization for Multimodal Sentiment Analysis. EMNLP 2021. [[paper]](https://arxiv.org/pdf/2109.00412.pdf) [[code]](https://github.com/declare-lab/Multimodal-Infomax)

 - Progressive modality reinforcement for human multimodal emotion recognition from unaligned multimodal sequences. CVPR2021. [[paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Lv_Progressive_Modality_Reinforcement_for_Human_Multimodal_Emotion_Recognition_From_Unaligned_CVPR_2021_paper.pdf)

 - M3er: Multiplicative multimodal emotion recognition using facial, textual, and speech cues. AAAI2020. [[paper]](https://ojs.aaai.org/index.php/AAAI/article/view/5492/5348)

 - Group gated fusion on attention-based bidirectional alignment for multimodal emotion recognition. InterSpeech2020.[[paper]](https://arxiv.org/pdf/2201.06309) [[code]](https://github.com/ppfliu/emotion-recognition)

## Emotion Recognition in Conversation (ERC)

 - M2FNet: Multi-modal Fusion Network for Emotion Recognition in Conversation. CVPR2022 [[paper]](https://openaccess.thecvf.com/content/CVPR2022W/MULA/papers/Chudasama_M2FNet_Multi-Modal_Fusion_Network_for_Emotion_Recognition_in_Conversation_CVPRW_2022_paper.pdf)

 - MM-DFN: Multimodal Dynamic Fusion Network for Emotion Recognition in Conversations. ICASSP2022 [[paper]](https://arxiv.org/pdf/2203.02385.pdf) [[code]](https://github.com/zerohd4869/MM-DFN)

 - MMGCN: Multimodal fusion via deep graph convolution network for emotion recognition in conversation. ACL/IJCNLP 2021 [[paper]](https://arxiv.org/pdf/2107.06779.pdf) [[code]](https://github.com/hujingwen6666/MMGCN)

 - Multimodal emotion recognition with high-level speech and text features. ASRU2021 [[paper]](https://arxiv.org/pdf/2111.10202) [[code]](https://github.com/mmakiuchi/multimodal_emotion_recognition)

 - Shapes of emotions: Multimodal emotion recognition in conversations via emotion shifts. arXiv2021 [[paper]](https://arxiv.org/pdf/2112.01938)

 - Context-Dependent Domain Adversarial Neural Network for Multimodal Emotion Recognition. InterSpeech2020 [[paper]](http://speakit.cn/file/Context-Dependent%20Domain%20Adversarial%20Neural%20Network%20for%20Multimodal%20Emotion%20Recognition.pdf)

 - Dialoguernn: An attentive rnn for emotion detection in conversations. AAAI2019 [[paper]](https://arxiv.org/pdf/1811.00405) [[code]](https://github.com/SenticNet/conv-emotion)
 
## Textual Dialogue Emotion Detection

 - Contrast and generation make BART a good dialogue emotion recognizer. AAAI2022 [[paper]](https://arxiv.org/pdf/2112.11202) [[code]](https://github.com/whatissimondoing/cog-bart)

 - Topic-driven and knowledge-aware transformer for dialogue emotion detection. ACL/IJCNLP2021 [[paper]](https://arxiv.org/pdf/2106.01071) [[code]](https://github.com/something678/TodKat)

 - Dialoguecrn: Contextual reasoning networks for emotion recognition in conversations. ACL/IJCNN2021 [[paper]](https://arxiv.org/pdf/2106.01978) [[code]](https://github.com/zerohd4869/DialogueCRN)
 
 - Cosmic: Commonsense knowledge for emotion identification in conversations. EMNLP2020 [[paper]](https://arxiv.org/pdf/2010.02795) [[code]](https://github.com/declare-lab/conv-emotion)

 - Higru: Hierarchical gated recurrent units for utterance-level emotion recognition. NAALC2019 [[paper]](https://arxiv.org/pdf/1904.04446) [[code]](https://github.com/wxjiao/HiGRUs)

 - Dialoguegcn: A graph convolutional neural network for emotion recognition in conversation. EMNLP/IJCNLP2019 [[paper]](https://arxiv.org/pdf/1908.11540) [[code]](https://github.com/SenticNet/conv-emotion)

 - Knowledge-enriched transformer for emotion detection in textual conversations. IJCNLP2019 [[paper]](https://arxiv.org/pdf/1909.10681) [[code]](https://github.com/zhongpeixiang/KET)

## Others

 - Is Discourse Role Important for Emotion Recognition in Conversation? AAAI2022 [[paper]](https://www.aaai.org/AAAI22Papers/AAAI-8365.OngD.pdf)

 - Fortunately, Discourse Markers Can Enhance Language Models for Sentiment Analysis. AAAI2022 [[paper]](https://arxiv.org/pdf/2201.02026)

 - Adversarial Soft Prompt Tuning for Cross-Domain Sentiment Analysis. ACL2022 [[paper]](https://aclanthology.org/2022.acl-long.174.pdf)

 - EmoCaps: Emotion Capsule based Model for Conversational Emotion Recognition. ACL2022 [[paper]](https://arxiv.org/pdf/2203.13504)

 - M3ED: Multi-modal Multi-scene Multi-label Emotional Dialogue Database. ACL2022 [[paper]](https://arxiv.org/pdf/2205.10237)

 - Dimensional emotion detection from categorical emotion. EMNLP2021 [[paper]](https://arxiv.org/pdf/1911.02499) [[code]](https://github.com/sungjoonpark/emotiondetection)

 - Emotion Inference in Multi-Turn Conversations with Addressee-Aware Module and Ensemble Strategy. EMNLP2021 [[paper]](https://aclanthology.org/2021.emnlp-main.320.pdf)

 - Past, present, and future: Conversational emotion recognition through structural modeling of psychological knowledge. EMNLP2021 [[paper]](https://aclanthology.org/2021.findings-emnlp.104.pdf) [[code]](https://github.com/leqsnan/skaig-erc)

 - DialogueTRM: Exploring multi-modal emotional dynamics in a conversation. EMNLP2021 [[paper]](https://aclanthology.org/2021.findings-emnlp.229.pdf)

 - Knowledge-Interactive Network with Sentiment Polarity Intensity-Aware Multi-Task Learning for Emotion Recognition in Conversations. EMNLP2021 [[paper]](https://aclanthology.org/2021.findings-emnlp.245.pdf)

 - A discourse-aware graph neural network for emotion recognition in multi-party conversation. EMNLP2021 [[paper]](https://aclanthology.org/2021.findings-emnlp.252.pdf)

 - Multimodal phased transformer for sentiment analysis. EMNLP2021 [[paper]](https://aclanthology.org/2021.emnlp-main.189.pdf) [[code]](https://github.com/chengjunyan1/SP-Transformer)

 - Which is making the contribution: Modulating unimodal and cross-modal dynamics for multimodal sentiment analysis. EMNLP2021 [[paper]](https://arxiv.org/pdf/2111.08451)

 - Few-shot emotion recognition in conversation with sequential prototypical networks. EMNLP2021 [[paper]](https://arxiv.org/pdf/2109.09366) [[code]](https://github.com/gguibon/protoseq)

